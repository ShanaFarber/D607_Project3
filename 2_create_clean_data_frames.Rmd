---
title: "DATA 607 - Project 3 - Data Cleaning / Tidying / Aggregation"
author: "Shoshana Farber"
date: "2023-03-09"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(snakecase)
library(DT)
```

## Loading the Data

```{r load-data}
# ai jobs web scrape csv
ai_jobs <- read.csv(url("https://raw.githubusercontent.com/ShanaFarber/D607_Project3/main/data/aiJobsDf.csv"), na.strings = c(""))

# usa jobs web scrape csvs
usa_jobs_data_analyst <- read.csv(url("https://raw.githubusercontent.com/kac624/D607_Project3/main/data/data_analyst_usa_jobs.csv"), na.strings = c(""))

usa_jobs_data_scientist <- read.csv(url("https://raw.githubusercontent.com/kac624/D607_Project3/main/data/data_scientist_usa_jobs.csv"), na.strings = c(""))

# combine usa jobs
usa_jobs <- rbind(usa_jobs_data_analyst, usa_jobs_data_scientist)

# nyc jobs csv download
nyc_jobs <- read.csv(url("https://raw.githubusercontent.com/ShanaFarber/D607_Project3/main/data/NYC_Jobs-2.csv"), na.strings = c(""))

# data analyst web scrape
data_analyst_jobs <- read.csv(url("https://raw.githubusercontent.com/ShanaFarber/D607_Project3/main/data/data_analyst_dot_com.csv"))
```

## Cleaning Up

### AI Jobs

This data was web scraped by Keith Collela from [ai-jobs.net](https://ai-jobs.net/) and combined into a csv file. 

Looking at the data frame for the AI Jobs listings, the `tags` column seems to be the data science skills that are required. There are also some skills that may be listed within the `description` of the job listing. 

The job titles can be found in the `url` column within the url for the job listing. The format for each url is "https://ai-jobs.net//job/#####-job-title/". We used the number portion of the url as an ID for the jobs in this data frame. 

```{r}
# extracting job id and job titles
ai_jobs_cleaned <- ai_jobs %>%
  mutate("job_id" = str_extract(ai_jobs$url, '[0-9]+'),
         "job_title" = str_extract(ai_jobs$url, '[0-9]+-[a-z(-?)]+'), 
         job_title = str_remove_all(job_title, "(\\d|/)"),
         job_title = str_replace_all(job_title, "-", " "))
```

Now let's extract the job type, level, and salary ranges from the `ai_jobs` data frame:

```{r include=FALSE}
# str_view(ai_jobs_cleaned$pay_level, "[A-Za-z]+(\\s[A-Za-z]+)?")
# str_view(ai_jobs_cleaned$pay_level, "[A-Za-z]+-level")
# str_view(ai_jobs_cleaned$pay_level, "[A-Z]+\\s\\w+(\\+)?(\\s-\\s\\w+)?")
```

```{r clean-ai-jobs}
ai_jobs_cleaned <- ai_jobs_cleaned %>%
  mutate("job_type" = str_extract(pay_level, "[A-Za-z]+(\\s[A-Za-z]+)?"),
         "job_level" = str_extract(pay_level, "[A-Za-z]+-level"),
         "salary_range" = str_extract(pay_level, "[A-Z]+\\s\\w+(\\+)?(\\s-\\s\\w+)?"),
         "salary_currency" = str_extract(salary_range, "[A-Z]+"),
         "salary_min" = as.numeric(str_extract(salary_range, "\\d+")) * 1000,
         "salary_max" = as.numeric(str_remove(str_extract(salary_range, "-\\s\\d+"), "-\\s")) * 1000)

ai_jobs_cleaned <- ai_jobs_cleaned %>%
  transmute(job_id,
            job_title,
            location, 
            salary_currency,
            salary_min,
            salary_max,
            "job_quals" = tags,
            "job_description" = description,
            "website" = "ai-jobs.net")
```

**Attempting to Create a Skills Dictionary**

Using the `job_id` I created a separate data frame with the skills from each job listing. This data frame has `job_id` as a foreign key for the main `ai_jobs` table. The skills here were extracted from what was originally the `tags` column and what has been renamed as `job_quals`.

```{r get-ai-skills}
########## extract skills from tags ##############

# create a list of the skills from each job posting
jobs_skills <- str_split(ai_jobs_cleaned$job_quals, ";(\\s)?")

# loop through each listing to split up all the skills and put it in a separate data frame
for (job in 1:length(ai_jobs_cleaned$job_id)) {
  temp_skills <- unlist(jobs_skills[job])
  
  temp <- data.frame("job_id" = rep(ai_jobs_cleaned$job_id[job], length(temp_skills)),
                     "skill" = temp_skills)
  
  if (job == 1) {
    ai_jobs_skills <- temp
  } else {
    ai_jobs_skills <- rbind(ai_jobs_skills, temp)
  }
}
```

I tried to create a dictionary of skills from different sources to match up skills in the job descriptions for the other websites.

I first initialized a dictionary with the skills extracted from the AI Jobs listings. I then combined this with a data set of skills that I compiled based on my own knowledge and Google searches for useful data science skills.

```{r skills-dictionary}
# initialize dictionary
skills_dictionary <- unique(ai_jobs_skills$skill)

# additional skills 
additional_skills <- read.csv(url("https://raw.githubusercontent.com/ShanaFarber/D607_Project3/main/data/ds_skills.csv"))
additional_skills <- additional_skills$skill

# add to skills_dictionary and remove redundancy
skills_dictionary <- c(skills_dictionary, additional_skills)
skills_dictionary <- unique(skills_dictionary)
skills_dictionary <- skills_dictionary[!is.na(skills_dictionary)]

# making sure there is no duplicate (based on capitalization)
length(unique(tolower(skills_dictionary))) == length(skills_dictionary)

# checking for redundant values
redundancy_check <- data.frame("skill" = skills_dictionary,
                               "lower_skill" = tolower(skills_dictionary))
                               
redundancy_check %>%
  count(lower_skill) %>%
  filter(n > 1)

redundancy_check %>%
  filter(lower_skill == "matlab")

# remove repeated value
skills_dictionary <- skills_dictionary[!skills_dictionary == "Matlab"]

length(unique(tolower(skills_dictionary))) == length(skills_dictionary)
```

I then created a function to cross check the skills in the dictionary against the job descriptions from the job listings. 

#### Function for Extracting Skills

Within the function, I combined `job_quals` and `job_description` to account for all places where there might be any skills listed. 

```{r skills-extract-func}
extractSkills <- function(job_df, dict) {
  job_id_and_skill <- c()
  
  # checking for R (programming language) or broader language use
  vis_and_r_check <- c("R"="(\\s|\\\\)R(\\s|,|\\\\)", "Data visualization"="visual", "Data collection" = "(Data collection|collect data)", "Data analysis" = "(Data analysis|analyze data)", "Communication" = "(Communication|communicate)", "Collaboration" = "(Collaboration|collaborate|collaborative)", "C" = "(\\s|\\\\)C(\\s|,|\\\\)", "C\\+\\+" = "C\\+\\+")

  for(i in 1:length(job_df$job_id)) {
    job_id <- job_df$job_id[i]
    search <- paste(job_df$job_quals[i], job_df$job_desciption[i])
  
    for (j in 1:length(dict)) {
      pat <- dict[j]
      
      if (!pat %in% names(vis_and_r_check)) {
        if (str_detect(tolower(search), tolower(pat))) {
        job_id_and_skill <- append(job_id_and_skill, paste(job_id, pat, sep = ","))
        }
      } else {
        new_pat <- vis_and_r_check[pat]
      
        if (str_detect(tolower(search), tolower(new_pat))) {
        job_id_and_skill <- append(job_id_and_skill, paste(job_id, pat, sep = ","))
        }
      }
    
    
    }
  }

  skills_df <- data.frame("job_id_and_skill" = job_id_and_skill) %>%
    separate(col = job_id_and_skill, into = c("job_id", "skill"), sep = ",")
  
  return(skills_df)
}
```

I then cross-checked `skills_dictionary` against `job_description` for AI Jobs to see if there were any more skills within the descriptions for listings that were not included in the tags.

```{r ai-jobs-skills}
ai_jobs_skills2 <- extractSkills(ai_jobs_cleaned, skills_dictionary)

# full join to original skills df to add additional skills without repeating
ai_jobs_skills <- full_join(ai_jobs_skills, ai_jobs_skills2, by = c("job_id", "skill"))

length(unique(ai_jobs_skills)$job_id) == length(ai_jobs_skills$job_id)
```

### USA Jobs

This csv file was generated by Kayleah Griffen by web scraping [usajobs.gov](https://www.usajobs.gov/). 

The data frame already includes a column for job title. The number from the url posting will become the `job_id`. We also need to extract the salary and skills. 

```{r clean-usa-jobs}
usa_jobs_cleaned <- usa_jobs %>%
  mutate("job_id" = str_extract(job_url, "\\d+"),
         job_title = str_remove(job_title, "\\s+"),
         job_summary = str_remove(job_summary, "\\s+Summary\\s+"),
         job_salary = str_extract(job_salary, "\\d+([-\\d]+)\\d"),
         "salary_currency" = "USD",
         "salary_min" = as.numeric(str_remove_all(str_extract(job_salary, "\\d+-\\d+-"), "-")),
         "salary_max" = as.numeric(str_remove_all(str_extract(job_salary, "-\\d+-\\d+"), "-")),
         job_quals = str_remove(job_quals, "\\s+Qualifications\\s+"),
         job_duties = str_remove(job_duties, "\\s+Help\\s+Duties\\s+"),
         location = case_when(str_detect(job_location, '(Anywhere|remote)') ~ 'Remote',
                              str_detect(job_location, 'Washington') ~ 'Washington DC',
                              TRUE ~ str_extract(job_location, '(?<= )[A-Z]{2}(?= )')))

usa_jobs_cleaned <- usa_jobs_cleaned %>%
  transmute(job_id,
            job_title,
            location,
            salary_currency,
            salary_min,
            salary_max,
            job_quals,
            "job_description" = paste(job_summary,job_duties),
            "website" = "usajobs.gov") %>%
  filter(!duplicated(job_id))
```

I used the function created above to extract the skills. 

```{r usa-jobs-skills}
usa_jobs_skills <- extractSkills(usa_jobs_cleaned, skills_dictionary)

# check for possible redundancy
length(unique(usa_jobs_skills)$job_id) == length(usa_jobs_skills$job_id)
```

### NYC Jobs

```{r clean-nyc-jobs}
# change column titles to snake_case
names(nyc_jobs) <- to_snake_case(names(nyc_jobs))

nyc_jobs_filtered <- nyc_jobs %>% 
  filter(str_detect(tolower(business_title), "data")) %>%
  filter(str_detect(tolower(business_title), "(analyst|engineer|developer|scientist)"))

nyc_jobs_cleaned <- nyc_jobs_filtered %>%
  transmute(job_id,
            "job_title" = business_title,
            "location" = "New York",
            salary_currency = "USD",
            "salary_min" = salary_range_from,
            "salary_max" = salary_range_to,
            "job_quals" = preferred_skills,
            job_description,
            "website" = "data.cityofnewyork.us") %>%
  filter(!is.na(job_quals))
```

Using the same iteration as above to extract the skills from `job_quals` and `job_qualifications`:

```{r nyc-jobs-skills}
nyc_jobs_skills <- extractSkills(nyc_jobs_cleaned, skills_dictionary)

# check for redundancy
length(unique(nyc_jobs_skills)$job_id) == length(nyc_jobs_skills$job_id)

# eliminate redundancy
nyc_jobs_skills <- unique(nyc_jobs_skills)
```

### Data Analyst Jobs

This csv file was generated by Kayleah Griffen by web scraping [dataanalyst.com](https://www.dataanalyst.com/). 

The data frame already includes a column for job title. There is no indication of job id for any of the listing, so the `X` column will be used as the `job_id`. Skills will be extracted from the `job_requirement` and `job_roles` columns renamed as `job_quals` and `job_descriptions` to fit the format previously created for the other data frames. 

The job id here seems to be a combination of the job title and then a series of number or letters afterward. 

```{r clean-data-analyst-jobs}
# determine countries in the data set for salary information
data_analyst_jobs %>%
  count(job_country)

# str_view(data_analyst_jobs$job_url, "\\w+-.+")

# clean the data frame
data_analyst_jobs_cleaned <- data_analyst_jobs %>%
    mutate("job_id" = str_extract(job_url, "\\w+-.+"),
           "salary_currency" = ifelse(job_country == "United States", "USD", "GBP"),
           "salary_min" =  as.numeric(str_remove_all(str_extract(job_salary, "-\\d+-"), "-")),
           "salary_max" = as.numeric(str_remove_all(str_extract(job_salary, "-\\d+$"), "-")))
  
data_analyst_jobs_cleaned <- data_analyst_jobs_cleaned %>%
  transmute(job_id,
            job_title,
            "location" = job_country,
            salary_currency,
            salary_min,
            salary_max,
            "job_quals" = str_remove(job_requirements, "\\s+"),
            "job_description" = str_remove(job_roles, "\\s+"),
            "website" = "dataanalyst.com") %>%
  filter(!is.na(job_quals))

# making sure each job_id is unique
length(unique(data_analyst_jobs_cleaned$job_id)) == length(data_analyst_jobs_cleaned$job_id)
```

Extracting the skills from the data analyst job listing:

```{r}
data_analyst_jobs_skills <- extractSkills(data_analyst_jobs_cleaned, skills_dictionary)

# checking for possible redundancy
length(unique(data_analyst_jobs_skills)$job_id) == length(data_analyst_jobs_skills$job_id)
```

## Combining Data Frames

To create a full data frame of all the job listing and all the skills, combine the jobs data sets into `job_listings` and the skills data sets into `skills`.

```{r combine-df}
job_listings <- ai_jobs_cleaned %>%
  rbind(usa_jobs_cleaned) %>%
  rbind(nyc_jobs_cleaned) %>%
  rbind(data_analyst_jobs_cleaned)

skills <- ai_jobs_skills %>%
  rbind(usa_jobs_skills) %>%
  rbind(nyc_jobs_skills) %>%
  rbind(data_analyst_jobs_skills)
```

Create separate CSV files for each required data frame to be analyzed. This will allow for quick loading for the analysis. 

```{r write-csvs, eval=F}
write.csv(job_listings, "output/job_listings.csv", row.names=F)

write.csv(skills, "output/skills.csv", row.names=F)
```
