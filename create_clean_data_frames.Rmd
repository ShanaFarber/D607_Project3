---
title: "DATA 607 - Project 3"
author: "Shoshana Farber"
date: "2023-03-09"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(snakecase)
library(DT)
```

## Loading the Data

```{r}
# ai jobs web scrape csv
ai_jobs <- read.csv(url("https://raw.githubusercontent.com/ShanaFarber/D607_Project3/main/data/aiJobsDf.csv"), na.strings = c(""))

# nyc jobs csv download
nyc_jobs <- read.csv(url("https://raw.githubusercontent.com/ShanaFarber/D607_Project3/main/data/NYC_Jobs-2.csv"), na.strings = c(""))

# usa jobs web scrapre csvs
usa_jobs_data_analyst <- read.csv(url("https://raw.githubusercontent.com/kac624/D607_Project3/main/data/data_analyst_usa_jobs.csv"), na.strings = c(""))

usa_jobs_data_scientist <- read.csv(url("https://raw.githubusercontent.com/kac624/D607_Project3/main/data/data_scientist_usa_jobs.csv"), na.strings = c(""))

# combine usa jobs
usa_jobs <- rbind(usa_jobs_data_analyst, usa_jobs_data_scientist)
```

## Cleaning Up

### AI Jobs

This data was web scraped by Keith Collela from [ai-jobs.net](https://ai-jobs.net/) and combined into a csv file. 

Looking at the data frame for the AI Jobs listings, the `tags` column seems to be the data science skills that are required. There are also some skills that may be listed within the `description` of the job listing. 

The job titles can be found in the `url` column within the url for the job listing. The format for each url is "https://ai-jobs.net//job/#####-job-title/". We used the number portion of the url as an ID for the jobs in this data frame. 

```{r}
# extracting job id and job titles
ai_jobs_cleaned <- ai_jobs %>%
  mutate("job_id" = str_extract(ai_jobs$url, '[0-9]+'),
         "job_title" = str_extract(ai_jobs$url, '[0-9]+-[a-z(-?)]+'), 
         job_title = str_remove_all(job_title, "(\\d|/)"),
         job_title = str_replace_all(job_title, "-", " "))
```

Now let's extract the job type, level, and salary ranges from the `ai_jobs` data frame:

```{r eval = FALSE}
str_view(ai_jobs_cleaned$pay_level, "[A-Za-z]+(\\s[A-Za-z]+)?")
str_view(ai_jobs_cleaned$pay_level, "[A-Za-z]+-level")
str_view(ai_jobs_cleaned$pay_level, "[A-Z]+\\s\\w+(\\+)?(\\s-\\s\\w+)?")
```

```{r}
ai_jobs_cleaned <- ai_jobs_cleaned %>%
  mutate("job_type" = str_extract(pay_level, "[A-Za-z]+(\\s[A-Za-z]+)?"),
         "job_level" = str_extract(pay_level, "[A-Za-z]+-level"),
         "salary_range" = str_extract(pay_level, "[A-Z]+\\s\\w+(\\+)?(\\s-\\s\\w+)?"),
         "salary_currency" = str_extract(salary_range, "[A-Z]+"),
         "salary_min" = as.numeric(str_extract(salary_range, "\\d+")) * 1000,
         "salary_max" = as.numeric(str_remove(str_extract(salary_range, "-\\s\\d+"), "-\\s")) * 1000)

ai_jobs_cleaned <- ai_jobs_cleaned %>%
  transmute(job_id,
            job_title,
            location, 
            job_type,
            job_level,
            salary_currency,
            salary_min,
            salary_max,
            tags,
            "website" = "ai-jobs.net")
```

Using the `job_id` we created a separate data frame with the skills from each job listing. This data frame has `job_id` as a foreign key for the main `ai_jobs` table. 

```{r}
########## extract skills from tags ##############

# create a list of the skills from each job posting
jobs_skills <- str_split(ai_jobs_cleaned$tags, ";(\\s)?")

# loop through each listing to split up all the skills and put it in a separate data frame
for (job in 1:length(ai_jobs_cleaned$job_id)) {
  temp_skills <- unlist(jobs_skills[job])
  
  temp <- data.frame("job_id" = rep(ai_jobs_cleaned$job_id[job], length(temp_skills)),
                     "skills" = temp_skills)
  
  if (job == 1) {
    ai_jobs_skills <- temp
  } else {
    ai_jobs_skills <- rbind(ai_jobs_skills, temp)
  }
}
```

**Attempting to Create a Skills Dictionary**

I tried to create a dictionary of skills from different sources to match up skills in the job descriptions for the other websites.

I first initialized a dictionary with the skills extracted from the AI Jobs listings.

```{r}
skills_dictionary <- unique(ai_jobs_skills$skills)
```

I the combined this with a data set of skills that I found online:

```{r}
# load skills csv
skills <- read.csv("C:/Users/Shoshana/Downloads/public_use-industry-skills-needs.csv", na.strings = c(""))

# clean up and extract skills
skills <-  unique(skills$skill_group_name)
skills <- str_remove_all(skills, "\\(.+\\)")

# add to skills_dictionary and remove redundancy
skills_dictionary <- c(skills_dictionary, skills)
skills_dictionary <- unique(skills_dictionary)
skills_dictionary <- skills_dictionary[!is.na(skills_dictionary)]
```

[Source](https://datacatalog.worldbank.org/search/dataset/0038027).

### USA Jobs

This csv file was generated by Kayleah Griffen by web scraping [usajobs.gov](https://www.usajobs.gov/). 

The data frame already includes a column for job title. The number from the url posting will become the `job_id`. We also need to extract the salary and skills. Extracting the skills here is trickier, as they are not nicely listed like in the AI Jobs data set. 

```{r}
usa_jobs_cleaned <- usa_jobs %>%
  mutate("job_id" = str_extract(job_url, "\\d+"),
         job_title,
         job_salary = str_extract(job_salary, "\\d+([-\\d]+)\\d"),
         "salary_currency" = "USD",
         "salary_min" = as.numeric(str_remove_all(str_extract(job_salary, "\\d+-\\d+-"), "-")),
         "salary_max" = as.numeric(str_remove_all(str_extract(job_salary, "-\\d+-\\d+"), "-")),
         job_quals = str_remove(job_quals, "Qualifications\\s+"))

usa_jobs_cleaned <- usa_jobs_cleaned %>%
  transmute(job_id,
            job_title,
            "location" = job_location, 
            salary_currency,
            salary_min,
            salary_max,
            job_quals,
            "website" = "usajobs.gov")
```

Trying to extract the skills from the job qualifications:

```{r}
job_id_and_skill <- c()

for(i in 1:length(usa_jobs_cleaned$job_id)) {
  job_id <- usa_jobs_cleaned$job_id[i]
  
  for (j in 1:length(skills_dictionary)) {
    pat <- skills_dictionary[j]
    
    if (pat != "R") {
      if (str_detect(tolower(usa_jobs_cleaned$job_quals[i]), tolower(pat))) {
      job_id_and_skill <- append(job_id_and_skill, paste(job_id, pat, sep = ","))
      }
    } else {
      quals <- str_replace_all(usa_jobs_cleaned$job_quals[i], " (\\s+)", ",")
      quals <- str_split(quals, ",")
      pat <- "^R$"
      
      if (str_detect(tolower(quals), tolower(pat))) {
      job_id_and_skill <- append(job_id_and_skill, paste(job_id, pat, sep = ","))
      }
    }
    
    
  }
}

usa_jobs_skills <- data.frame("job_id_and_skill" = job_id_and_skill) %>%
  separate(col = job_id_and_skill, into = c("job_id", "skill"), sep = ",")
``` 
